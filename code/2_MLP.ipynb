{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wda9yWHVWnMY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# implementation MLP\n",
        "M = 64 # taille couche cachée\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1=torch.nn.Linear(1, M) # couche cachée\n",
        "        self.fc2=torch.nn.Linear(M, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.functional.F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = MLP()\n",
        "\n",
        "# test\n",
        "print(model)\n",
        "print(list(model.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# implémenter data sets\n",
        "N_TRAIN = 200\n",
        "\n",
        "class My_Dataset(Dataset):\n",
        "  '''\n",
        "  Hérite de l'objet Dataset qui facilite la gestion des données.\n",
        "  data:\n",
        "        data_x: shape = (N, 1)\n",
        "        data_y: shape = (N, 1)\n",
        "        N est le nombre de données\n",
        "        x et y sont scalaires\n",
        "  '''\n",
        "  def __init__(self, N = 100):\n",
        "    # génerer données\n",
        "    x = np.random.uniform(0, 1, size=(N, 1))\n",
        "    y = np.sin(2 * np.pi * x) + np.random.normal(scale=.1, size=(N, 1))\n",
        "    # mémoriser (le MLP nécessite des float sur 32 bits)\n",
        "    self.data_x = np.float32(x)\n",
        "    self.data_y = np.float32(y)\n",
        "    self.N = N\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.N\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # retourne un couple (x, y)\n",
        "    return self.data_x[index, :], self.data_y[index, :]\n",
        "\n",
        "# train set, with mini-batch\n",
        "train_data = My_Dataset(N_TRAIN)\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "\n",
        "valid_data = My_Dataset(50)\n",
        "valid_loader = DataLoader(valid_data, batch_size=len(valid_data))\n",
        "\n",
        "# test\n",
        "print(\"tailles : train %i  valid %i\" % (len(train_data), len(valid_data))) # utilise __len___\n",
        "print(\"échantillon : x, y = \", train_data[0]) # utilise __getitem__"
      ],
      "metadata": {
        "id": "KfJKaLo8YiKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrainement du MLP\n",
        "LEARNING_RATE = 1e-1\n",
        "EPOCHS = 2000\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # entrainement\n",
        "    train_losses = []\n",
        "    for x, y in train_loader:\n",
        "        # evaluer fonction cout\n",
        "        y_predict = model(x)\n",
        "        loss = ((y_predict - y)**2).mean()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # mise à jour paramètre\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # vaidation\n",
        "    with torch.no_grad(): # pas besoin de calcul de gradient\n",
        "        for i, (x, y) in enumerate(valid_loader):\n",
        "            assert(i == 0) # une seule boucle (pas de mini-batch)\n",
        "            y_predict = model(x)\n",
        "            valid_loss = ((y_predict - y)**2).mean().item()\n",
        "    if epoch % 10 == 0:\n",
        "      print('epoch %i train %.2e  valid %.2e' % (epoch, np.mean(train_losses),\n",
        "                                                 valid_loss))\n"
      ],
      "metadata": {
        "id": "z2up3E6McC8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualiser résultat\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(x.numpy(), y.numpy(), 'o', x.numpy(), y_predict.numpy(), 'o')\n",
        "plt.title('M=%i epochs=%i LR=%.2e' % (M, EPOCHS, LEARNING_RATE))\n",
        "plt.legend(['data valid', 'MLP'])\n"
      ],
      "metadata": {
        "id": "KmB1AUsqOD11"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}